{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CVDL-project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshudaur/TensorFlowProjects/blob/master/CVDL_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apfj4pmLtab5",
        "colab_type": "code",
        "outputId": "7cdf2242-5eb5-46e5-a060-a9c85172f1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2by2GDK14RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "# data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "#                                          fname='flower_photos', untar=True)\n",
        "# # print(data_dir)\n",
        "# data_dir = pathlib.Path(data_dir)\n",
        "# print(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3lybLMltzq9",
        "colab_type": "code",
        "outputId": "9d3fbd73-cdb8-40d3-98c3-3a4eb9c21b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/CVDL_Project/dataset/'  #change dir to your project folder"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXl5wXsI14RQ",
        "colab_type": "code",
        "outputId": "2c05f569-7e66-421f-eac1-5c7390842bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_dir=pathlib.Path(root_path+'train')\n",
        "print(data_dir)\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "image_count"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive/My Drive/CVDL_Project/dataset/train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4918"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap09ctN014RT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynG-2RGj14RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "BATCH_SIZE = 64\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "# STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "# print(CLASS_NAMES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx-TVrkT14RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
        "#                                                      batch_size=BATCH_SIZE,\n",
        "#                                                      shuffle=True,\n",
        "#                                                      target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "#                                                      classes = list(CLASS_NAMES))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUbHiRT_14RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjV6mTeL14Rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_batch, label_batch = next(train_data_gen)\n",
        "# show_batch(image_batch, label_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5uLiDmi14Re",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "878a1ce2-15bf-4b01-93e0-f44dd82e61dd"
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-753fd6958fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'*/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(file_pattern, shuffle, seed)\u001b[0m\n\u001b[1;32m    822\u001b[0m       file_pattern = ops.convert_to_tensor(\n\u001b[1;32m    823\u001b[0m           file_pattern, dtype=dtypes.string, name=\"file_pattern\")\n\u001b[0;32m--> 824\u001b[0;31m       \u001b[0mmatching_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0;31m# Raise an exception if `file_pattern` does not match any files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mmatching_files\u001b[0;34m(pattern, name)\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: train; No such file or directory [Op:MatchingFiles]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH9q_0lO14Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh2ISFe514Rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfxBrpoF14Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ekZGCtD14Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "# print(labeled_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOSU2URL14Rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image, label in labeled_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "#   print(\"Label: \", label.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kbhbf1314Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=6000):\n",
        "  # This is a small dataset, only load it once, and keep it in memory.\n",
        "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "  # fit in memory.\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKbc9US114Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_batch, label_batch = next(iter(labeled_ds))\n",
        "# data = tf.data.Dataset.from_tensor_slices(\n",
        "#     (image_batch.reshape(image_batch.shape[0],224,224,3).astype(np.float32) / 255, label_batch.astype(np.int32)))\n",
        "# data = data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "train_ds = prepare_for_training(labeled_ds)\n",
        "\n",
        "image_batch, label_batch = next(iter(train_ds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsbW7tyT14Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0VXLyMC14R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "layer_list = [layers.Conv2D(128, (3, 3), activation='tanh', input_shape=(224, 224, 3)),\n",
        "              layers.Conv2D(128, (3, 3), activation='tanh'),\n",
        "              layers.Conv2D(256, (3, 3), activation='tanh'),layers.Conv2D(256, (3, 3), activation='tanh'),\n",
        "              layers.Flatten(),layers.Dense(102)]\n",
        "\n",
        "model = tf.keras.Sequential(layer_list)\n",
        "\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "# from_logits = True!! #neverforget\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6X6Ubn-14R3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=opt, loss=loss_fn, metrics=[train_acc_metric])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0K6SfQA14R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKAoUnEx14R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(image_batch, steps_per_epoch=1000, epochs=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5uZVSaP14R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}